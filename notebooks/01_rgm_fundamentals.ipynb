{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3ceecb6",
   "metadata": {},
   "source": [
    "# Experiment 1: RGM Fundamentals (Visualizing Renormalization)\n",
    "\n",
    "이 노트북은 **Spatial Renormalizing Generative Model (RGM)**의 핵심 원리인 **\"Renormalization (재규격화)\"** 과정을 시각적으로 증명하는 독립적인 실험입니다.\n",
    "\n",
    "RGM의 핵심 가설은 다음과 같습니다:\n",
    "> \"세상은 계층적(Hierarchical)이며, 국소적인 세부 사항(Local Details)은 상위 레벨에서 추상적인 개념(Abstract Concepts)으로 통합(Renormalized)된다.\"\n",
    "\n",
    "이 실험에서는 다음 세 가지를 검증합니다:\n",
    "1.  **Abstraction (추상화)**: 픽셀(Pixels) $\\to$ 국소 특징($z_1$) $\\to$ 전역 개념($z_2$)으로 정보가 압축되는 과정.\n",
    "2.  **Instantiation (구체화)**: 동일한 전역 개념($z_2$)이 다양한 국소 특징($z_1$)으로 발현되는 과정 (One Concept, Many Variations).\n",
    "3.  **Locality (국소성)**: $z_1$의 변화는 이미지의 특정 영역에만 영향을 미치며, 이는 $z_1$이 공간적 위상(Spatial Topology)을 보존함을 의미함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "318bf381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# 1. Setup and Imports\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Add project root to path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from src.models.spatial_rgm import SpatialRGM\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9322278c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RGM for demonstration...\n",
      "Epoch 1/3, Loss: 0.6217\n",
      "Epoch 1/3, Loss: 0.6217\n",
      "Epoch 2/3, Loss: 0.1968\n",
      "Epoch 2/3, Loss: 0.1968\n",
      "Epoch 3/3, Loss: 0.1688\n",
      "Epoch 3/3, Loss: 0.1688\n"
     ]
    }
   ],
   "source": [
    "# 2. Prepare Data and Model\n",
    "# Load MNIST\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "dataset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Initialize Model\n",
    "model = SpatialRGM(latent_dim=32, num_classes=10).to(device)\n",
    "\n",
    "# Quick Training Function (if no pretrained model exists)\n",
    "def train_quick(model, loader, epochs=3):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    print(\"Training RGM for demonstration...\")\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            # Note: We need to access internal variables, so we might need to modify forward or just use the modules directly\n",
    "            # But SpatialRGM.forward returns reconstruction. We need to implement a custom loss here similar to the experiment class\n",
    "            # For simplicity, let's just use the model's components or a simplified training loop\n",
    "            \n",
    "            # Re-implementing basic loss logic from MNISTExperiment for standalone execution\n",
    "            h1 = model.enc1(x)\n",
    "            z1_logits = model.z1_proj(h1)\n",
    "            z1_sample = model.reparameterize_gumbel(z1_logits)\n",
    "            z2_logits = model.enc2(z1_sample)\n",
    "            z2_sample = model.reparameterize_gumbel(z2_logits)\n",
    "            z1_prior_logits = model.dec2(z2_sample).view(-1, model.latent_dim, 7, 7)\n",
    "            recon = model.dec1(z1_sample)\n",
    "            \n",
    "            # Losses\n",
    "            recon_loss = F.mse_loss(recon, x)\n",
    "            cls_loss = F.cross_entropy(z2_logits, y)\n",
    "            \n",
    "            # Prior matching (z1 posterior vs z1 prior)\n",
    "            # Simple KL divergence approximation for categorical\n",
    "            p = F.softmax(z1_logits, dim=1)\n",
    "            q = F.softmax(z1_prior_logits, dim=1)\n",
    "            prior_loss = torch.sum(p * (torch.log(p + 1e-8) - torch.log(q + 1e-8))) / (x.size(0) * 49)\n",
    "            \n",
    "            loss = recon_loss + 1.0 * cls_loss + 0.1 * prior_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(loader):.4f}\")\n",
    "\n",
    "# Train the model\n",
    "train_quick(model, loader, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249539d9",
   "metadata": {},
   "source": [
    "## Experiment 1: Hierarchical Abstraction (Bottom-Up)\n",
    "이미지가 어떻게 $z_1$ (7x7 Grid)과 $z_2$ (Global Class)로 압축되는지 시각화합니다.\n",
    "- **Input**: 원본 이미지 (28x28)\n",
    "- **Level 1 ($z_1$)**: 7x7 그리드의 각 셀이 어떤 특징을 잡고 있는지 확인.\n",
    "- **Level 2 ($z_2$)**: 최종적으로 어떤 숫자로 인식했는지 확인."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026a6ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "x, y = next(iter(loader))\n",
    "x = x[0:1].to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Level 1\n",
    "    h1 = model.enc1(x)\n",
    "    z1_logits = model.z1_proj(h1)\n",
    "    z1_idx = z1_logits.argmax(dim=1) # (1, 7, 7) - Discrete codes\n",
    "    \n",
    "    # Level 2\n",
    "    z1_sample = model.reparameterize_gumbel(z1_logits)\n",
    "    z2_logits = model.enc2(z1_sample)\n",
    "    pred_class = z2_logits.argmax(dim=1).item()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Input Image\")\n",
    "plt.imshow(x[0, 0].cpu(), cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(f\"Level 1: z1 Codes (7x7)\\n(Local Features)\")\n",
    "plt.imshow(z1_idx[0].cpu(), cmap='tab20')\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(f\"Level 2: z2 Prediction\\n(Global Concept: {pred_class})\")\n",
    "plt.bar(range(10), F.softmax(z2_logits, dim=1)[0].cpu().numpy())\n",
    "plt.xticks(range(10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d731ec14",
   "metadata": {},
   "source": [
    "## Experiment 2: Concept-Conditional Generation (Top-Down)\n",
    "**\"개념(Concept)은 하나지만, 표현(Instance)은 다양하다.\"**\n",
    "\n",
    "상위 레벨 변수 $z_2$를 고정(예: 숫자 '3')하고, 하위 레벨 변수 $z_1$을 $P(z_1|z_2)$에서 여러 번 샘플링하여 복원합니다.\n",
    "이 실험은 $z_2$가 **\"무엇(What)\"**을 결정하고, $z_1$이 **\"어떻게(How)\"**를 결정한다는 것을 증명합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be21e1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_digit = 3\n",
    "num_samples = 5\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "with torch.no_grad():\n",
    "    # 1. Fix z2 (One-hot vector for target_digit)\n",
    "    z2_fixed = torch.zeros(num_samples, 10).to(device)\n",
    "    z2_fixed[:, target_digit] = 1.0\n",
    "    \n",
    "    # 2. Predict z1 Prior from z2\n",
    "    z1_prior_logits = model.dec2(z2_fixed).view(num_samples, 32, 7, 7)\n",
    "    \n",
    "    # 3. Sample z1 from this prior (Stochasticity comes from here)\n",
    "    # We use Gumbel-Softmax to sample diverse z1 codes\n",
    "    z1_sampled = F.gumbel_softmax(z1_prior_logits, tau=1.0, hard=True)\n",
    "    \n",
    "    # 4. Decode to Pixels\n",
    "    generated = model.dec1(z1_sampled)\n",
    "\n",
    "for i in range(num_samples):\n",
    "    plt.subplot(1, num_samples, i+1)\n",
    "    plt.title(f\"Sample {i+1} (Digit {target_digit})\")\n",
    "    plt.imshow(generated[i, 0].cpu(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.suptitle(f\"Fixed Concept z2={target_digit} -> Diverse Instances via z1 Sampling\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcafc712",
   "metadata": {},
   "source": [
    "## Experiment 3: Local vs Global Perturbation\n",
    "**\"Renormalization은 공간적 정보를 보존하면서 압축한다.\"**\n",
    "\n",
    "1.  **Local Perturbation**: $z_1$ (7x7) 그리드에서 **단 하나의 셀**만 값을 변경했을 때, 이미지의 **해당 위치**만 변하는지 확인합니다.\n",
    "2.  **Global Perturbation**: $z_2$ (숫자 클래스)를 변경했을 때, 이미지가 **전역적으로** 변하는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd2ffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Image\n",
    "x, _ = next(iter(loader))\n",
    "x = x[0:1].to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Encode to get base z1\n",
    "    h1 = model.enc1(x)\n",
    "    z1_logits = model.z1_proj(h1)\n",
    "    z1_hard = model.reparameterize_gumbel(z1_logits)\n",
    "    \n",
    "    # --- 1. Local Perturbation ---\n",
    "    # Modify the center cell (3, 3) of z1\n",
    "    z1_perturbed = z1_hard.clone()\n",
    "    # Shift the categorical code by 1 (cyclic)\n",
    "    current_code = z1_perturbed[0, :, 3, 3].argmax()\n",
    "    new_code = (current_code + 5) % 32 # Change to a different code\n",
    "    z1_perturbed[0, :, 3, 3] = 0\n",
    "    z1_perturbed[0, new_code, 3, 3] = 1\n",
    "    \n",
    "    recon_base = model.dec1(z1_hard)\n",
    "    recon_local = model.dec1(z1_perturbed)\n",
    "    \n",
    "    # --- 2. Global Perturbation ---\n",
    "    # Change z2 class\n",
    "    z2_logits = model.enc2(z1_hard)\n",
    "    z2_hard = model.reparameterize_gumbel(z2_logits)\n",
    "    current_class = z2_hard.argmax(dim=1).item()\n",
    "    target_class = (current_class + 1) % 10\n",
    "    \n",
    "    z2_new = torch.zeros_like(z2_hard)\n",
    "    z2_new[0, target_class] = 1.0\n",
    "    \n",
    "    # Predict new z1 from new z2\n",
    "    z1_from_new_z2 = model.dec2(z2_new).view(1, 32, 7, 7)\n",
    "    z1_from_new_z2 = F.gumbel_softmax(z1_from_new_z2, hard=True)\n",
    "    recon_global = model.dec1(z1_from_new_z2)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.title(\"Original\")\n",
    "plt.imshow(recon_base[0, 0].cpu(), cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.title(\"Local Perturbation\\n(Center z1 changed)\")\n",
    "plt.imshow(recon_local[0, 0].cpu(), cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.title(\"Difference (Local)\")\n",
    "diff = torch.abs(recon_base - recon_local)\n",
    "plt.imshow(diff[0, 0].cpu(), cmap='hot')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.title(f\"Global Perturbation\\n(Class {current_class}->{target_class})\")\n",
    "plt.imshow(recon_global[0, 0].cpu(), cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
